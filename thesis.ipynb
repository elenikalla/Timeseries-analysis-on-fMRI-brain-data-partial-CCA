{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "from nilearn.maskers import NiftiLabelsMasker\n",
    "from nilearn import datasets, image\n",
    "\n",
    "# === Define Subject IDs ===\n",
    "# subject_ids = [\n",
    "#     \"sub-0001\", \"sub-0002\", \"sub-0003\", \"sub-0004\", \"sub-0005\",\n",
    "#     \"sub-0006\", \"sub-0007\", \"sub-0008\", \"sub-0009\", \"sub-0011\"\n",
    "# ]\n",
    "# subject_ids = [\n",
    "#     \"sub-0001\", \"sub-0002\"\n",
    "# ]\n",
    "subject_ids = [\n",
    "    \"sub-0001\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Header of fMRI task data: (3.0, 3.0, 3.3, 2.0)\n",
      "Shape of fMRI taskdata: (80, 80, 36, 160)\n"
     ]
    }
   ],
   "source": [
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# === Load NIfTI Image ===\n",
    "img_task = nib.load(\"sub-0001_task-workingmemory_acq-seq_bold.nii.gz\")\n",
    "data_task = img_task.get_fdata()  # Shape: (X, Y, Z, T)\n",
    "header_task = img_task.header\n",
    "print(\"Header of fMRI task data:\",header_task.get_zooms())\n",
    "print(\"Shape of fMRI taskdata:\", data_task.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Header of fMRI rest data: (3.0, 3.0, 3.3, 2.0)\n",
      "Shape of fMRI rest data: (80, 80, 36, 240)\n"
     ]
    }
   ],
   "source": [
    "img_rest = nib.load(\"sub-0001_task-restingstate_acq-seq_bold.nii.gz\")\n",
    "data_rest = img_rest.get_fdata()  # Shape: (X, Y, Z, T)\n",
    "header_rest = img_rest.header\n",
    "print(\"Header of fMRI rest data:\",header_rest.get_zooms())\n",
    "print(\"Shape of fMRI rest data:\", data_rest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Construct File Paths ===\n",
    "fmri_rest_files = [f\"{sid}_task-restingstate_acq-seq_bold.nii.gz\" for sid in subject_ids]\n",
    "fmri_task_files = [f\"{sid}_task-workingmemory_acq-seq_bold.nii.gz\" for sid in subject_ids]\n",
    "tsv_files = [f\"{sid}.tsv\" for sid in subject_ids]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[get_dataset_dir] Dataset found in C:\\Users\\elena\\nilearn_data\\schaefer_2018\n"
     ]
    }
   ],
   "source": [
    "# === Load Atlas and Define Masker ===\n",
    "atlas = datasets.fetch_atlas_schaefer_2018(n_rois=100)\n",
    "masker = NiftiLabelsMasker(atlas.maps, standardize=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def build_trial_wise_matrix(time_series_task, time_series_rest, tsv_path, TR=2.0, fixed_len=3):\n",
    "    \"\"\"\n",
    "    Επιστρέφει αντίστοιχα blocks task και rest για κάθε trial, με βάση τα onset του .tsv.\n",
    "\n",
    "    Parameters:\n",
    "    - time_series_task: NumPy array (T_task, R)\n",
    "    - time_series_rest: NumPy array (T_rest, R)\n",
    "    - tsv_path: string, path προς .tsv αρχείο\n",
    "    - TR: χρονική διάρκεια TR σε δευτερόλεπτα\n",
    "    - fixed_len: αριθμός TRs ανά trial block (default: 3)\n",
    "\n",
    "    Returns:\n",
    "    - task_matrix: NumPy array (n_trials, fixed_len, n_rois)\n",
    "    - rest_matrix: NumPy array (n_trials, fixed_len, n_rois)\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(tsv_path, sep=\"\\t\")\n",
    "    n_timepoints_task, n_rois = time_series_task.shape\n",
    "    n_timepoints_rest = time_series_rest.shape[0]\n",
    "\n",
    "    task_matrix = []\n",
    "    rest_matrix = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        onset = row[\"onset\"]\n",
    "        start_tr = int(np.floor(onset / TR))\n",
    "        end_tr = start_tr + fixed_len\n",
    "\n",
    "        # Skip trial αν δεν χωράει ούτε σε task ούτε σε rest\n",
    "        if end_tr > n_timepoints_task or end_tr > n_timepoints_rest:\n",
    "            continue\n",
    "\n",
    "        block_task = time_series_task[start_tr:end_tr]\n",
    "        block_rest = time_series_rest[start_tr:end_tr]\n",
    "\n",
    "        task_matrix.append(block_task)\n",
    "        rest_matrix.append(block_rest)\n",
    "\n",
    "    return np.array(task_matrix), np.array(rest_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing sub-0001\n"
     ]
    }
   ],
   "source": [
    "subject_task_data = {}\n",
    "subject_rest_data = {}\n",
    "\n",
    "for sid, rest_file, task_file, tsv_file in zip(subject_ids, fmri_rest_files, fmri_task_files, tsv_files):\n",
    "    print(f\"Processing {sid}\")\n",
    "\n",
    "    img_task = nib.load(task_file)\n",
    "    img_rest = nib.load(rest_file)\n",
    "\n",
    "    ts_task = masker.fit_transform(img_task)\n",
    "    ts_rest = masker.transform(img_rest)\n",
    "\n",
    "    task_matrix, rest_matrix = build_trial_wise_matrix(ts_task, ts_rest, tsv_file)\n",
    "\n",
    "    subject_task_data[sid] = task_matrix\n",
    "    subject_rest_data[sid] = rest_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject sub-0001 task data shape (40, 3, 100)\n",
      "Subject sub-0001 rest data shape (40, 3, 100)\n"
     ]
    }
   ],
   "source": [
    "for sid,sid in zip(subject_task_data,subject_rest_data):\n",
    "    print(f\"Subject {sid} task data shape\",subject_task_data[sid].shape)\n",
    "    print(f\"Subject {sid} rest data shape\",subject_rest_data[sid].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_roi_correlation_matrix(data):\n",
    "    \"\"\"\n",
    "    Υπολογίζει Pearson correlation matrix μεταξύ ROIs,\n",
    "    flattening όλα τα TRs από όλα τα trials.\n",
    "\n",
    "    Parameters:\n",
    "    - data: NumPy array (n_trials, 3, n_rois)\n",
    "\n",
    "    Returns:\n",
    "    - corr_matrix: NumPy array (n_rois, n_rois)\n",
    "    \"\"\"\n",
    "    n_trials, n_trs, n_rois = data.shape\n",
    "    flat_data = data.reshape(-1, n_rois)  # shape: (n_trials * 3, n_rois)\n",
    "\n",
    "    corr_matrix = np.corrcoef(flat_data.T)  # (n_rois, n_rois)\n",
    "    return corr_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject sub-0001 task data correlation (100, 100)\n",
      "Subject sub-0001 rest data correlation (100, 100)\n"
     ]
    }
   ],
   "source": [
    "task_corr_dict = {}\n",
    "rest_corr_dict = {}\n",
    "\n",
    "for sid in subject_ids:\n",
    "    task_corr = compute_roi_correlation_matrix(subject_task_data[sid])\n",
    "    rest_corr = compute_roi_correlation_matrix(subject_rest_data[sid])\n",
    "\n",
    "    task_corr_dict[sid]=task_corr\n",
    "    rest_corr_dict[sid]=rest_corr\n",
    "\n",
    "\n",
    "for sid,sid in zip(task_corr_dict,rest_corr_dict):\n",
    "    print(f\"Subject {sid} task data correlation\",task_corr_dict[sid].shape)\n",
    "    print(f\"Subject {sid} rest data correlation\",task_corr_dict[sid].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def compute_partial_pearson_matrix(data, num_components=3):\n",
    "    \"\"\"\n",
    "    Υπολογίζει πίνακα Partial Pearson Correlation μεταξύ ROIs,\n",
    "    αφαιρώντας κοινή πληροφορία μέσω PCA (σε flatten δεδομένα από trials).\n",
    "\n",
    "    Parameters:\n",
    "    - data: NumPy array (n_trials, n_TRs, n_rois)\n",
    "    - num_components: Αριθμός PCA components που θα αφαιρεθούν ως confounds\n",
    "\n",
    "    Returns:\n",
    "    - partial_corr_matrix: NumPy array (n_rois, n_rois) συμμετρικός\n",
    "    \"\"\"\n",
    "    n_trials, n_trs, n_rois = data.shape\n",
    "    flat_data = data.reshape(-1, n_rois)\n",
    "\n",
    "    partial_corr_matrix = np.eye(n_rois)\n",
    "\n",
    "    for i in range(n_rois):\n",
    "        for j in range(i + 1, n_rois):\n",
    "            X = flat_data[:, i].reshape(-1, 1)\n",
    "            Y = flat_data[:, j].reshape(-1, 1)\n",
    "\n",
    "            other_indices = [k for k in range(n_rois) if k != i and k != j]\n",
    "            Z = flat_data[:, other_indices]\n",
    "\n",
    "            num_components\n",
    "            Z_pca = PCA(n_components=num_components).fit_transform(Z)\n",
    "\n",
    "            def regress_out(A, Z_pca):\n",
    "                reg = LinearRegression().fit(Z_pca, A)\n",
    "                return A - reg.predict(Z_pca)\n",
    "\n",
    "            X_resid = regress_out(X, Z_pca).flatten()\n",
    "            Y_resid = regress_out(Y, Z_pca).flatten()\n",
    "\n",
    "            corr = np.corrcoef(X_resid, Y_resid)[0, 1]\n",
    "            partial_corr_matrix[i, j] = corr\n",
    "            partial_corr_matrix[j, i] = corr\n",
    "\n",
    "    return partial_corr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject sub-0001 task data partial correlation (100, 100)\n",
      "Subject sub-0001 rest data partial correlation (100, 100)\n"
     ]
    }
   ],
   "source": [
    "task_part_corr_dict = {}\n",
    "rest_part_corr_dict = {}\n",
    "\n",
    "for sid in subject_ids:\n",
    "    task_part_corr = compute_partial_pearson_matrix(subject_task_data[sid])\n",
    "    rest_part_corr = compute_partial_pearson_matrix(subject_rest_data[sid])\n",
    "\n",
    "    task_part_corr_dict[sid]=task_part_corr\n",
    "    rest_part_corr_dict[sid]=rest_part_corr\n",
    "    print(f\"Subject {sid} task data partial correlation\",task_part_corr_dict[sid].shape)\n",
    "    print(f\"Subject {sid} rest data partial correlation\",rest_part_corr_dict[sid].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cross_decomposition import CCA\n",
    "\n",
    "def compute_cca_matrix_across_trials(data, n_components=1):\n",
    "    \"\"\"\n",
    "    Υπολογίζει Canonical Correlation μεταξύ κάθε ζεύγους ROIs,\n",
    "    χωρίς flatten — χρησιμοποιώντας τα 3 TRs ανά trial ως μεταβλητές.\n",
    "\n",
    "    Parameters:\n",
    "    - data: NumPy array (n_trials, 3, n_rois)\n",
    "    - n_components: αριθμός CCA components (συνήθως 1)\n",
    "\n",
    "    Returns:\n",
    "    - cca_matrix: NumPy array (n_rois, n_rois), συμμετρικός\n",
    "    \"\"\"\n",
    "    n_trials, n_trs, n_rois = data.shape\n",
    "    cca_matrix = np.eye(n_rois)\n",
    "\n",
    "    for i in range(n_rois):\n",
    "        for j in range(i + 1, n_rois):\n",
    "            X = data[:, :, i]  # shape: (n_trials, 3)\n",
    "            Y = data[:, :, j]  # shape: (n_trials, 3)\n",
    "\n",
    "            cca = CCA(n_components=n_components)\n",
    "            X_c, Y_c = cca.fit_transform(X, Y)\n",
    "\n",
    "            # Υπολογίζουμε την Pearson correlation του 1ου canonical pair\n",
    "            corr = np.corrcoef(X_c[:, 0], Y_c[:, 0])[0, 1]\n",
    "            cca_matrix[i, j] = corr\n",
    "            cca_matrix[j, i] = corr\n",
    "\n",
    "    return cca_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.linalg import eig,pinv\n",
    "\n",
    "def compute_cca_matrix_across_trials_linear(data, n_components=1):\n",
    "    \"\"\"\n",
    "    Υπολογίζει Canonical Correlation μεταξύ κάθε ζεύγους ROIs,\n",
    "    με χρήση αλγεβρας (χωρίς sklearn), across trials.\n",
    "\n",
    "    Parameters:\n",
    "    - data: NumPy array (n_trials, 3, n_rois)\n",
    "    - n_components: αριθμός CCA components (συνήθως 1)\n",
    "\n",
    "    Returns:\n",
    "    - cca_matrix: NumPy array (n_rois, n_rois), συμμετρικός\n",
    "    \"\"\"\n",
    "    n_trials, n_trs, n_rois = data.shape\n",
    "    cca_matrix = np.eye(n_rois)\n",
    "\n",
    "    def center(A):\n",
    "        return A - A.mean(axis=0, keepdims=True)\n",
    "\n",
    "    def cov(A, B):\n",
    "        A = center(A)\n",
    "        B = center(B)\n",
    "        return A.T @ B / (A.shape[0] - 1)\n",
    "\n",
    "    for i in range(n_rois):\n",
    "        for j in range(i + 1, n_rois):\n",
    "            # Each ROI is (n_trials, 3)\n",
    "            X = data[:, :, i]\n",
    "            Y = data[:, :, j]\n",
    "\n",
    "            # Centered covariance matrices\n",
    "            Sxx = cov(X, X)\n",
    "            Syy = cov(Y, Y)\n",
    "            Sxy = cov(X, Y)\n",
    "            Syx = Sxy.T\n",
    "\n",
    "            # Form generalized eigenvalue problem\n",
    "            A = np.block([\n",
    "                [np.zeros_like(Sxy), Sxy],\n",
    "                [Syx, np.zeros_like(Syx)]\n",
    "            ])\n",
    "            B = np.block([\n",
    "                [Sxx, np.zeros_like(Sxy)],\n",
    "                [np.zeros_like(Syx), Syy]\n",
    "            ])\n",
    "\n",
    "            # Solve generalized eigenproblem\n",
    "            eigvals, _ = eig(A, B)\n",
    "            eigvals = np.real(eigvals)\n",
    "            canonical_corrs = np.sort(np.abs(eigvals))[::-1]\n",
    "\n",
    "            rho = canonical_corrs[0] if canonical_corrs.size > 0 else 0.0\n",
    "            cca_matrix[i, j] = rho\n",
    "            cca_matrix[j, i] = rho\n",
    "\n",
    "    return cca_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom: [[1.         0.51553911 0.73055565 ... 0.73033738 0.77613211 0.66972917]\n",
      " [0.51553911 1.         0.83662915 ... 0.69353741 0.37447917 0.48290861]\n",
      " [0.73055565 0.83662915 1.         ... 0.64702463 0.75728619 0.61242187]\n",
      " ...\n",
      " [0.73033738 0.69353741 0.64702463 ... 1.         0.61375815 0.6584022 ]\n",
      " [0.77613211 0.37447917 0.75728619 ... 0.61375815 1.         0.82249635]\n",
      " [0.66972917 0.48290861 0.61242187 ... 0.6584022  0.82249635 1.        ]] Sklearn: [[1.         0.51553896 0.73055538 ... 0.73033723 0.77613124 0.66972911]\n",
      " [0.51553896 1.         0.83662899 ... 0.69353735 0.37447888 0.48290842]\n",
      " [0.73055538 0.83662899 1.         ... 0.64702457 0.75728608 0.61242165]\n",
      " ...\n",
      " [0.73033723 0.69353735 0.64702457 ... 1.         0.61375786 0.65840215]\n",
      " [0.77613124 0.37447888 0.75728608 ... 0.61375786 1.         0.82249581]\n",
      " [0.66972911 0.48290842 0.61242165 ... 0.65840215 0.82249581 1.        ]]\n",
      "Max diff: 0.0032532972263871196\n"
     ]
    }
   ],
   "source": [
    "for sid in subject_ids:\n",
    "    corr1 = compute_cca_matrix_across_trials_linear(subject_task_data[sid])\n",
    "    corr2 = compute_cca_matrix_across_trials(subject_task_data[sid])\n",
    "    # print(\"Custom:\", corr1, \"Sklearn:\", corr2)\n",
    "print(\"Max diff:\", np.abs(corr1 - corr2).max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject sub-0001 task data cca (100, 100)\n",
      "Subject sub-0001 rest data cca (100, 100)\n"
     ]
    }
   ],
   "source": [
    "task_cca_dict = {}\n",
    "rest_cca_dict = {}\n",
    "\n",
    "for sid in subject_ids:\n",
    "    task_cca = compute_cca_matrix_across_trials(subject_task_data[sid])\n",
    "    rest_cca = compute_cca_matrix_across_trials(subject_rest_data[sid])\n",
    "\n",
    "    task_cca_dict[sid]=task_cca\n",
    "    rest_cca_dict[sid]=rest_cca\n",
    "    print(f\"Subject {sid} task data cca\",task_cca_dict[sid].shape)\n",
    "    print(f\"Subject {sid} rest data cca\",task_cca_dict[sid].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.linalg import eig\n",
    "\n",
    "def compute_pcca_per_trial_with_topkZ(trial_data, i, j, cca_matrix, k=2):\n",
    "    \"\"\"\n",
    "    Computes PCCA between ROI i and j in a single trial,\n",
    "    using top-k confounding ROIs selected from cca_matrix.\n",
    "\n",
    "    Parameters:\n",
    "    - trial_data: shape (3, n_rois) for one trial\n",
    "    - i, j: indices of X and Y ROIs\n",
    "    - cca_matrix: shape (n_rois, n_rois)\n",
    "    - k: number of ROIs to use in Z\n",
    "\n",
    "    Returns:\n",
    "    - pcca_rho: partial canonical correlation (scalar)\n",
    "    \"\"\"\n",
    "    X = trial_data[:, i].reshape(-1, 1)\n",
    "    Y = trial_data[:, j].reshape(-1, 1)\n",
    "\n",
    "    # Select top-k confounding ROIs based on CCA matrix\n",
    "    candidate_indices = [z for z in range(trial_data.shape[1]) if z != i and z != j]\n",
    "    relevance_scores = [max(cca_matrix[i, z], cca_matrix[j, z]) for z in candidate_indices]\n",
    "    top_k_indices = [candidate_indices[z] for z in np.argsort(relevance_scores)[-k:]]\n",
    "\n",
    "    Z = trial_data[:, top_k_indices]  # shape (3, k)\n",
    "\n",
    "    # Covariance helpers\n",
    "    def center(A): return A - A.mean(axis=0, keepdims=True)\n",
    "    def cov(A, B): return center(A).T @ center(B) / (A.shape[0] - 1)\n",
    "\n",
    "    # Covariances\n",
    "    Sxz = cov(X, Z)\n",
    "    Syz = cov(Y, Z)\n",
    "    Szz = cov(Z, Z)\n",
    "    Sxy = cov(X, Y)\n",
    "    Sxx = cov(X, X)\n",
    "    Syy = cov(Y, Y)\n",
    "\n",
    "    # Partial covariances\n",
    "    inv_Szz = np.linalg.pinv(Szz)\n",
    "    Sxy_z = Sxy - Sxz @ inv_Szz @ Syz.T\n",
    "    Syx_z = Sxy_z.T\n",
    "    Sxx_z = Sxx - Sxz @ inv_Szz @ Sxz.T\n",
    "    Syy_z = Syy - Syz @ inv_Szz @ Syz.T\n",
    "\n",
    "    # Generalized eigenvalue problem\n",
    "    A = np.block([\n",
    "        [np.zeros_like(Sxy_z), Sxy_z],\n",
    "        [Syx_z, np.zeros_like(Syx_z)]\n",
    "    ])\n",
    "    B = np.block([\n",
    "        [Sxx_z, np.zeros_like(Sxy_z)],\n",
    "        [np.zeros_like(Syx_z), Syy_z]\n",
    "    ])\n",
    "\n",
    "    eigvals, _ = eig(A, B)\n",
    "    eigvals = np.real(eigvals)\n",
    "    canonical_corrs = np.sort(np.abs(eigvals))[::-1]\n",
    "\n",
    "    return canonical_corrs[0] if canonical_corrs.size > 0 else 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_pcca_tensor(data, cca_matrix, k=2):\n",
    "    \"\"\"\n",
    "    Computes the full PCCA tensor:\n",
    "    shape = (n_trials, n_rois, n_rois)\n",
    "\n",
    "    Parameters:\n",
    "    - data: shape (n_trials, 3, n_rois)\n",
    "    - cca_matrix: shape (n_rois, n_rois), from compute_cca_matrix_across_trials\n",
    "    - k: number of top confounding ROIs to use in Z\n",
    "\n",
    "    Returns:\n",
    "    - pcca_tensor: (n_trials, n_rois, n_rois)\n",
    "    \"\"\"\n",
    "    n_trials, _, n_rois = data.shape\n",
    "    pcca_tensor = np.zeros((n_trials, n_rois, n_rois))\n",
    "\n",
    "    for t in range(n_trials):\n",
    "        trial = data[t]  # shape (3, n_rois)\n",
    "        for i in range(n_rois):\n",
    "            for j in range(i + 1, n_rois):\n",
    "                pcca_val = compute_pcca_per_trial_with_topkZ(trial, i, j, cca_matrix, k)\n",
    "                pcca_tensor[t, i, j] = pcca_val\n",
    "                pcca_tensor[t, j, i] = pcca_val  # symmetric\n",
    "\n",
    "    return pcca_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_pcca_dict = {}\n",
    "rest_pcca_dict = {}\n",
    "\n",
    "for sid in subject_ids:\n",
    "    task_pcca = compute_pcca_tensor(subject_task_data[sid],task_cca_dict[sid])\n",
    "    rest_pcca = compute_pcca_tensor(subject_rest_data[sid],rest_cca_dict[sid])\n",
    "\n",
    "    task_pcca_dict[sid]=task_pcca\n",
    "    rest_pcca_dict[sid]=rest_pcca\n",
    "    print(f\"Subject {sid} task data pcca\",task_pcca_dict[sid].shape)\n",
    "    print(f\"Subject {sid} rest data pcca\",rest_pcca_dict[sid].shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
